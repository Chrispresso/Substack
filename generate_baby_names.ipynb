{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcAyr6Amt-fI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import requests\n",
        "import string\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_sequence, pack_padded_sequence, pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar, RichProgressBar\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "import pytorch_lightning as pl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "KRzJhe9Jufnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download a list of baby names:"
      ],
      "metadata": {
        "id": "VNuazS6vustg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/hadley/data-baby-names/master/baby-names.csv'\n",
        "content = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "oEqJOyYEuf23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['name', 'sex']].drop_duplicates().reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xUp127jAuyse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['sex'].value_counts())"
      ],
      "metadata": {
        "id": "-xHNrvKyu7v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_vals = df['name'].value_counts()\n",
        "df_vals[df_vals==2]"
      ],
      "metadata": {
        "id": "w8W8j06Ku-iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unique = df['name'].drop_duplicates().reset_index(drop=True)\n",
        "len(df_unique)"
      ],
      "metadata": {
        "id": "NhGqurp2vXx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = .8\n",
        "val_percent = .1\n",
        "test_percent = .1\n",
        "\n",
        "df_train = df_unique.sample(frac=train_percent, random_state=0xC0FFEE)\n",
        "df_val_test = df_unique.drop(df_train.index).sample(frac=1.0, random_state=0xC0FFEE)\n",
        "df_val = df_val_test.sample(frac=0.5, random_state=0xC0FFEE)\n",
        "df_test = df_val_test.drop(df_val.index)"
      ],
      "metadata": {
        "id": "F7Mm1ILkxtwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totals = len(df_train), len(df_val), len(df_test)\n",
        "print(totals, sum(totals))"
      ],
      "metadata": {
        "id": "Bl5GvKPl2OcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = ['<pad>'] + ['<sos>'] + list(string.ascii_lowercase) + ['<eos>']\n",
        "char_to_idx = {char:idx for idx,char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for char,idx in char_to_idx.items()}\n",
        "vocab_size = len(char_to_idx)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "FQV2qMB537VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_idx['a']"
      ],
      "metadata": {
        "id": "dIj7980W4As6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_char[2]"
      ],
      "metadata": {
        "id": "cM7Ge_jG5gEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenized_names(df):\n",
        "  # Handle series and df - a bit lazy, but this is fine here\n",
        "  try:\n",
        "    names = df['name'].values\n",
        "  except:\n",
        "    names = df.values\n",
        "  ret = []\n",
        "  for name in names:\n",
        "    name = name.lower()\n",
        "    toks = ['<sos>'] + list(name) + ['<eos>']\n",
        "    ret.append(toks)\n",
        "  return ret"
      ],
      "metadata": {
        "id": "9W3Usizq9hl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_tokenized_names(df_val)[:5]"
      ],
      "metadata": {
        "id": "vTYkdrwt-DRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LM(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      vocab_size: int,\n",
        "      embedding_dim: int,\n",
        "      hidden_dim: int,\n",
        "      num_layers: int\n",
        "    ):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(\n",
        "        embedding_dim, hidden_dim, num_layers,\n",
        "        bidirectional=True, batch_first=True\n",
        "    )\n",
        "    self.fc = nn.Linear(2 * hidden_dim,vocab_size)\n",
        "\n",
        "  def forward(self, seqs):\n",
        "    # Count the non-pad tokens\n",
        "    seq_lens = torch.count_nonzero(seqs, dim=1).cpu()\n",
        "    embeddings = self.embedding(seqs)\n",
        "\n",
        "    # Feed through LSTM\n",
        "    _, (hn, _) = self.lstm(\n",
        "        nn.utils.rnn.pack_padded_sequence(\n",
        "            embeddings,\n",
        "            seq_lens,\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False\n",
        "        )\n",
        "    )\n",
        "    # Save off hidden state before FC\n",
        "    self.hidden = torch.cat((hn[0], hn[1]), dim=1)\n",
        "    out = self.fc(self.hidden)\n",
        "    return out\n",
        "\n",
        "lm = LM(vocab_size, 8, 64, 2)\n",
        "lm"
      ],
      "metadata": {
        "id": "Shj7ts0f5iNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, tokenized_names, char_to_id):\n",
        "    self.tok_names = tokenized_names\n",
        "    self.char_to_id = char_to_id\n",
        "\n",
        "    self._samples = []\n",
        "    for tok_name in self.tok_names:\n",
        "      for i in range(len(tok_name) - 1):\n",
        "        partial_seq = [self.char_to_id[tok] for tok in tok_name[:i + 1]]\n",
        "        next_tok = self.char_to_id[tok_name[i+1]]\n",
        "        self._samples.append((partial_seq, next_tok))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._samples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self._samples[idx]"
      ],
      "metadata": {
        "id": "U4E2kmA483ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_names = get_tokenized_names(df_val)\n",
        "val_ds = NameDataset(val_names, char_to_idx)\n",
        "val_ds[:len(val_names[0])-1]\n",
        "\n"
      ],
      "metadata": {
        "id": "47q_HniI_WRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for partial, next_tok in val_ds[:len(val_names[0])-1]:\n",
        "  for tok in partial:\n",
        "    print(idx_to_char[tok], end=' ')\n",
        "  print('->', idx_to_char[next_tok])"
      ],
      "metadata": {
        "id": "1a83l_7n_qjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "  partials, next_toks = [], []\n",
        "  for (partial, next_tok) in batch:\n",
        "    partials.append(torch.tensor(partial))\n",
        "    next_toks.append(next_tok)\n",
        "\n",
        "  return (\n",
        "      pad_sequence(partials, batch_first=True, padding_value=0),\n",
        "      torch.tensor(next_toks)\n",
        "  )"
      ],
      "metadata": {
        "id": "accQGdpKBzCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(DataLoader(val_ds, batch_size=2))) # Don't work cause they ain't all equal bro"
      ],
      "metadata": {
        "id": "3mbUqHvRCzWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(DataLoader(val_ds, batch_size=3, collate_fn=collate, shuffle=True)))"
      ],
      "metadata": {
        "id": "82ca-pHiC3VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "     NameDataset(get_tokenized_names(df_train), char_to_idx),\n",
        "     batch_size=256,\n",
        "     collate_fn=collate,\n",
        "     shuffle=True\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "     NameDataset(get_tokenized_names(df_val), char_to_idx),\n",
        "     batch_size=256,\n",
        "     collate_fn=collate,\n",
        "     shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "nHlT9-AFDAAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "  def __init__(self, encoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "\n",
        "  def _generic_step(self, batch, batch_idx):\n",
        "    X, y = batch\n",
        "    out = self.encoder(X)\n",
        "    loss = F.cross_entropy(out, y)\n",
        "    return loss\n",
        "\n",
        "  def forward(self, seq):\n",
        "    return self.encoder(seq)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    return self._generic_step(batch, batch_idx)\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss = self._generic_step(batch, batch_idx)\n",
        "    self.log('val_loss', loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    opt = torch.optim.Adam(self.encoder.parameters(), lr=2e-3)\n",
        "    return opt"
      ],
      "metadata": {
        "id": "efSJ88j0Ex21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LM(vocab_size, 8, 64, 2)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using', device)\n",
        "lit_model = LitModel(encoder)\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='auto', # or `device` from above\n",
        "    max_epochs=100,\n",
        "    log_every_n_steps=25,\n",
        "    callbacks=[\n",
        "        RichProgressBar(refresh_rate=50),\n",
        "        EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainer.fit(lit_model, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "id": "bOHtwASTIgRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create a deep copy of the encoder and replace the fully connected layer with an Identity. This makes it so when we call `forward()` we instead return the `self.hidden` rather than the multi-class distribution."
      ],
      "metadata": {
        "id": "AuqJnfkKnHOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "df_unseen = df.loc[df_test.index]\n",
        "enc = copy.deepcopy(lit_model.encoder).eval()\n",
        "enc.fc = nn.Identity()\n",
        "enc"
      ],
      "metadata": {
        "id": "IytAdW36s03d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def name2token_ids(name):\n",
        "  tok_name = ['<sos>'] + list(name.lower()) + ['<eos>']\n",
        "  ids = [char_to_idx[tok] for tok in tok_name]\n",
        "  return torch.tensor(ids).unsqueeze(0)"
      ],
      "metadata": {
        "id": "BO_QY9zanfbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the shape is now the 128 dimension vector!"
      ],
      "metadata": {
        "id": "l40XAufjo1uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc(name2token_ids('chris')).shape"
      ],
      "metadata": {
        "id": "FwqOsO5mSzGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning"
      ],
      "metadata": {
        "id": "64tdNKoDnmGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unseen_train = df_unseen.sample(frac=.5, random_state=0xC0FFEE)\n",
        "df_useen_val_test = df_unseen.drop(df_unseen_train.index).sample(frac=1.0, random_state=0xC0FFEE)\n",
        "df_unseen_val = df_useen_val_test.sample(frac=0.1, random_state=0xC0FFEE)\n",
        "df_unseen_test = df_useen_val_test.drop(df_unseen_val.index)\n",
        "\n",
        "print(len(df_unseen), len(df_unseen_train), len(df_unseen_val), len(df_unseen_test))"
      ],
      "metadata": {
        "id": "pDacBi0ny0j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unseen_train"
      ],
      "metadata": {
        "id": "UowXS8Ywuohv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unseen_train.sex.value_counts()"
      ],
      "metadata": {
        "id": "9k1hGFu0pcJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameSexDataset(Dataset):\n",
        "  def __init__(self, df, char_to_idx):\n",
        "    tokenized_names = get_tokenized_names(df)\n",
        "    self.char_to_idx = char_to_idx\n",
        "    self._samples = []\n",
        "    boy = [0, 1]\n",
        "    girl = [1, 0]\n",
        "    sexes = {\n",
        "        'boy':boy,\n",
        "        'girl':girl\n",
        "    }\n",
        "\n",
        "    for tok_name, sex in zip(tokenized_names, df['sex'].values):\n",
        "      ids = [char_to_idx[tok] for tok in tok_name]\n",
        "      self._samples.append((ids, sexes[sex]))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self._samples[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._samples)\n"
      ],
      "metadata": {
        "id": "75wjBFwD0XZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_name_sex(batch):\n",
        "  names, sexes = [], []\n",
        "  for (name, sex) in batch:\n",
        "    names.append(torch.tensor(name))\n",
        "    sexes.append(sex)\n",
        "\n",
        "  return (\n",
        "      pad_sequence(names, batch_first=True, padding_value=0),\n",
        "      torch.tensor(sexes).float()\n",
        "  )\n"
      ],
      "metadata": {
        "id": "LUNmfv9yxEv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SexPredictor(nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(128, hidden_dim)\n",
        "    self.out = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.l1(x))\n",
        "    out = self.out(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "7esPTwbBz12B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_train_dataloader = DataLoader(\n",
        "     NameSexDataset(df_unseen_train, char_to_idx),\n",
        "     batch_size=32,\n",
        "     collate_fn=collate_name_sex,\n",
        "     shuffle=True\n",
        ")\n",
        "\n",
        "unseen_val_dataloader = DataLoader(\n",
        "     NameSexDataset(df_unseen_val, char_to_idx),\n",
        "     batch_size=32,\n",
        "     collate_fn=collate_name_sex,\n",
        "     shuffle=True\n",
        ")\n",
        "\n",
        "unseen_test_dataloader = DataLoader(\n",
        "     NameSexDataset(df_unseen_test, char_to_idx),\n",
        "     batch_size=len(df_unseen_test),\n",
        "     collate_fn=collate_name_sex,\n",
        "     shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "fpwgTH_h0wzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LitModelPredictor(pl.LightningModule):\n",
        "  def __init__(self, model, enc):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.enc = enc.eval()\n",
        "    for param in self.enc.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def _generic_step(self, batch, batch_idx):\n",
        "    X, y = batch\n",
        "    with torch.no_grad():\n",
        "      name_vec = self.enc(X)\n",
        "    out = self.model(name_vec)\n",
        "    loss = F.binary_cross_entropy_with_logits(out, y)\n",
        "    return loss\n",
        "\n",
        "  def forward(self, seq):\n",
        "    with torch.no_grad():\n",
        "      name_vec = self.enc(seq)\n",
        "    return self.model(name_vec)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    return self._generic_step(batch, batch_idx)\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss = self._generic_step(batch, batch_idx)\n",
        "    self.log('val_loss', loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    opt = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "    return opt"
      ],
      "metadata": {
        "id": "uaF6Tt2d1RGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = SexPredictor(64)\n",
        "\n",
        "lit_model_pred = LitModelPredictor(predictor, enc)\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='auto',\n",
        "    max_epochs=100,\n",
        "    log_every_n_steps=25,\n",
        "    callbacks=[\n",
        "        RichProgressBar(refresh_rate=50),\n",
        "        EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainer.fit(lit_model_pred, unseen_train_dataloader, unseen_val_dataloader)"
      ],
      "metadata": {
        "id": "SXhAszwB2Uma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model_pred = lit_model_pred.eval()\n",
        "with torch.no_grad():\n",
        "  X, y = next(iter(unseen_test_dataloader))\n",
        "  out = lit_model_pred(X).argmax(dim=-1)\n",
        "  acc = (out == y.argmax(dim=-1)).float().mean()\n",
        "  print('accuracy', acc)\n",
        "lit_model_pred = lit_model_pred.train()\n",
        "# trainer.test(lit_model, unseen_test_dataloader)"
      ],
      "metadata": {
        "id": "9hgECmEU6r3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unseen_test['sex'].value_counts()"
      ],
      "metadata": {
        "id": "87Or9zA68T4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad! We froze the weights from the original encoder and used just the output from it to train a smaller network with ~8.4k weights. We also fine-tuned on a smaller amount of data and still ended up with almost 77% accuracy on the test set! That's pretty good!"
      ],
      "metadata": {
        "id": "bYoJ38FWt83G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding schemes\n"
      ],
      "metadata": {
        "id": "iGsUvHTRqhuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_letter(encoder, partial, char_to_idx, idx_to_char, n=1):\n",
        "  encoder.train(False)\n",
        "  with torch.no_grad():\n",
        "    seq = ['<sos>'] + list(partial)\n",
        "    seq_ids = [char_to_idx[ch] for ch in seq]\n",
        "    seq_tensor = torch.tensor(seq_ids).unsqueeze(0)\n",
        "    out = F.softmax(encoder(seq_tensor), dim=-1)\n",
        "    probs, idxs = torch.sort(out, descending=True)\n",
        "    probs = probs.cpu().numpy().flatten()[:n]\n",
        "    idxs = idxs.cpu().numpy().flatten()[:n]\n",
        "    next_char = [idx_to_char[idx] for idx in idxs]\n",
        "\n",
        "  encoder.train(True)\n",
        "  return next_char, probs"
      ],
      "metadata": {
        "id": "lxHuDN1xO_TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_letter(lit_model.encoder, 'chri', char_to_idx, idx_to_char, n=5)"
      ],
      "metadata": {
        "id": "7p5rwI_GREXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def greedy_decoder(encoder, max_len, char_to_idx, idx_to_char, partial_name=''):\n",
        "  ret = partial_name\n",
        "  curr_len = len(ret)\n",
        "  curr_tok = None\n",
        "  total_prob = 0\n",
        "\n",
        "  while curr_tok != '<eos>' and curr_len < max_len:\n",
        "    curr_toks, probs = predict_next_letter(encoder, ret, char_to_idx, idx_to_char)\n",
        "    curr_tok = curr_toks[0]\n",
        "    prob = probs[0]\n",
        "    total_prob += math.log(prob)\n",
        "    if curr_tok != '<eos>':\n",
        "      ret += curr_tok\n",
        "  return ret, math.exp(total_prob)"
      ],
      "metadata": {
        "id": "XGQ5TdvkRNOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decoder(lit_model.encoder, 20, char_to_idx, idx_to_char)"
      ],
      "metadata": {
        "id": "c6zo9t84SpHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decoder(lit_model.encoder, 20, char_to_idx, idx_to_char, partial_name='b')"
      ],
      "metadata": {
        "id": "WSGDpknEStOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decoder(lit_model.encoder, 20, char_to_idx, idx_to_char, partial_name='c')"
      ],
      "metadata": {
        "id": "pix_0bfaTcCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decoder(lit_model.encoder, 20, char_to_idx, idx_to_char, partial_name='chr')"
      ],
      "metadata": {
        "id": "C40aeB2sUcpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toks, probs = predict_next_letter(lit_model.encoder, 'a', char_to_idx, idx_to_char, n=len(idx_to_char))\n",
        "nucleus = 0.9\n",
        "curr = 0\n",
        "for i, p in enumerate(probs):\n",
        "    curr += p\n",
        "    if curr >= nucleus:\n",
        "        break\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
        "ax.plot(probs)\n",
        "plt.title(f'Most probable from \"a\" with nucleus={nucleus}')\n",
        "plt.xticks(list(range(len(probs))), toks, rotation=70)\n",
        "plt.axvline(x=i + 1, color='r')\n",
        "plt.show()\n",
        "\n",
        "print(np.sum(probs[:i + 1]))\n",
        "print('tokens needed', toks[:i + 1])\n",
        "print(f'Total tokens: {i+1}, % toks needed for 90% nucleus: ' +\\\n",
        "  f'{(i+1)/len(idx_to_char)*100:,.02f}%')"
      ],
      "metadata": {
        "id": "iCApk3j3UjGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nucleus_decoder(encoder, max_len, idx_to_char, char_to_idx, partial='', nucleus=.9):\n",
        "  partial_seq = partial\n",
        "  ret_prob = 0\n",
        "  while True:\n",
        "    toks, probs = predict_next_letter(encoder, partial_seq, char_to_idx, idx_to_char, len(idx_to_char))\n",
        "    curr = 0\n",
        "    for i, p in enumerate(probs):\n",
        "      curr += p\n",
        "      if curr >= nucleus:\n",
        "        break\n",
        "\n",
        "    candidates = toks[: i + 1]\n",
        "    candidate_probs = probs[: i + 1]\n",
        "    # Re-distribute the probs\n",
        "    new_probs = candidate_probs / sum(candidate_probs)\n",
        "\n",
        "    # Sample the characters with their probs\n",
        "    next_char = np.random.choice(candidates, p=new_probs)\n",
        "    idx = candidates.index(next_char)\n",
        "    prob = candidate_probs[idx]\n",
        "    ret_prob += math.log(prob)\n",
        "    if next_char != '<eos>':\n",
        "      partial_seq += next_char\n",
        "\n",
        "    if next_char == '<eos>' or len(partial_seq) == (max_len - 1):\n",
        "      break\n",
        "\n",
        "  return partial_seq, math.exp(ret_prob)\n"
      ],
      "metadata": {
        "id": "U_kZlI92Vk8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "for _ in range(10):\n",
        "  name, prob = (nucleus_decoder(lit_model.encoder, 20, idx_to_char, char_to_idx))\n",
        "  print(name, prob)\n",
        "  name = name.capitalize()\n",
        "  in_train = name in df_train.values\n",
        "  in_val = name in df_val.values\n",
        "  original = not in_train and not in_val\n",
        "  print(f'Name is{\" \" if original else \" not\"} original')"
      ],
      "metadata": {
        "id": "Df5KSsPJqyaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-yP-Bxqve5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}